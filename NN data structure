// This code defines the data structures of each element present in a neural network
// It will contain structs that define neurons, layers of neurons, matricies for weights
// Matricies for biases and some linear algebra functions.

#include<stdio.h>
#include<stdlib.h>
#include<math.h>

// Neuron is something that holds a value.
// It need to have decimal precison, hence float is chosen.
struct neuron {
    float activation;
};

// Neuron layer consists of N neurons that is specified by constructor
// So a neuron layer can de described using an array of neurons, hence the following struct.
struct neuron_layer {
    struct neuron*N;
    int num_neurons; 
};

// Weight matrix is a 2d matrix that consists of, 
// all the weight values that connect 2 layers. Will need a weight matrix constructor.
struct weight_matrix {
    int rows;
    int cols;
    float**weights;
};

/*
A matrix that biases the neuron's activation value, This is subtracted from the 
product of weight matrix and neuron layer matrix to give the activation values of 
the next matrix.
*/
struct bias_matrix{
    int size;
    float*bias;
};

/// @brief constructs a neuron layer with each neuron containing a random number between 0 and 1 
struct neuron_layer* layer_constructor(int num_neurons){
    struct neuron_layer*layer = (struct neuron_layer*)malloc(sizeof(struct neuron_layer));
    layer->num_neurons = num_neurons;
    layer->N = (struct neuron*)malloc(num_neurons*sizeof(struct neuron));
    if(layer->N == NULL){printf("Failed to Allocate memory"); exit(1);}
    for(int i = 0; i < num_neurons; i++){
        layer->N[i].activation = ((float)rand() / RAND_MAX) - 0.5;
    }
    return layer;
}

/// @brief Constructs a matrix of weights with randomly assigned values
struct weight_matrix* weight_matrix_constructor(int rows, int cols){
    struct weight_matrix*W = (struct weight_matrix*)malloc(sizeof(struct weight_matrix));
    W->rows = rows;
    W->cols = cols;

    W->weights = (float**)malloc(rows*sizeof(float*));
    if(W->weights == NULL){printf("Failed to Allocate memory"); exit(1);}
    for(int i = 0; i < rows; i++){
        W->weights[i] = (float*)malloc(cols*sizeof(float));
        if(W->weights[i] == NULL){printf("Failed to Allocate memory"); exit(1);}
    }

    for(int i = 0; i< rows; i++){
        for(int j = 0; j < cols; j++){
            W->weights[i][j] = ((float)rand() / RAND_MAX) - 0.5;
        }
    }
    return W;
}

/// @brief Constructs a bias matrix with random values
struct bias_matrix* bias_matrix_constructor(int cols){
    struct bias_matrix*B = (struct bias_matrix*)malloc(sizeof(struct bias_matrix));
    B->size = cols;
    B->bias = (float*)malloc(cols*sizeof(float));
    if(B->bias == NULL){printf("Failed to Allocate memory"); exit(1);}
    for(int i = 0; i < cols; i++){
        B->bias[i] = ((float)rand() / RAND_MAX) - 0.5;
    }
    return B;
}

/// @brief Frees the weight matrix
/// @param weight_matrix 
void destroy_weight_matrix(struct weight_matrix* weight_matrix) {
    if (weight_matrix == NULL) {
        return; // Nothing to do if the pointer is NULL
    }
    // Free each row of weights
    for (int i = 0; i < weight_matrix->rows; i++) {
        if (weight_matrix->weights[i] != NULL) {
            free(weight_matrix->weights[i]);
            weight_matrix->weights[i] = NULL; // Prevent dangling pointer
        }
    }
    // Free the weights pointer array
    if (weight_matrix->weights != NULL) {
        free(weight_matrix->weights);
        weight_matrix->weights = NULL; // Prevent dangling pointer
    }
}


/// @brief destroys and frees space for the neuron layer
/// @param layer 
void destroy_layer(struct neuron_layer* layer){
    if (layer->N != NULL) {
        free(layer->N);
        layer->N = NULL;
    }
    layer->num_neurons = 0;
}

/// @brief To be used for add biases from the layer's activation values
/// @param a Neuron Layer
/// @param b Bias Matrix
void add_matricies(struct neuron_layer *a, struct bias_matrix *b){
    if(a->num_neurons != b->size)
    {printf("matricies are incorrect in size, check again"); exit(1);}
    int size = a->num_neurons;
    for(int i = 0; i < size; i++){
        a->N[i].activation += b->bias[i];
    }
}

/// @brief Executes a dot product operation between the weight matrix and neuron layer
/// @param a initial neuron layer
/// @param w weight matrix
/// @param result resulting neuron layer, to be passed so values can be modified.
void matrix_dot_product(struct neuron_layer *a, struct weight_matrix *w, struct neuron_layer*result){
    if(a->num_neurons != w->cols)
    {printf("matricies are incorrect in size, check again"); exit(1);}
    int row = w->rows;
    for(int i = 0; i< row; i++){
        float prodsum;
        for(int j = 0; j< w->cols; j++){
            prodsum += a->N[j].activation * w->weights[i][j];
        }
        result->N[i].activation = prodsum;
    }
}

/// @brief Does one step of forward propogation
/// @param W Weight matrix
/// @param B Bias matrix
/// @param A1 Initial neuron layer
/// @param A2 Next neuron layer
void forward_propogate_step(struct weight_matrix*W,struct bias_matrix*B, struct neuron_layer* A1, struct neuron_layer*A2){
    matrix_dot_product(A1,W,A2);
    add_bias_matrix(A2,B);
    ReLU(A2);
}

/// @brief Applies Rectified Linear Unit function to the neurons in the later
/// @param A Neuron layer to which the ReLU is applied.
void ReLU(struct neuron_layer*A){
    int k = A->num_neurons;
    for(int i = 0; i < k; i++){
        if(A->N[i].activation < 0){ A->N[i].activation = 0.0;}
    }
}

/// @brief Applies softmax to the final output layer.
/// @param A Final output layer
void softmax(struct neuron_layer* A){
    int k = A->num_neurons;
    int expsum;
    for (int i = 0; i < k; i++){
        expsum += exp(A->N[i].activation);
    }
    for (int i = 0; i < k; i++){
        A->N[i].activation = exp(A->N[i].activation)/expsum;
    }
}

int main(){
    struct neuron_layer*A1 = layer_constructor(784);
    struct weight_matrix*W1 = weight_matrix_constructor(10,784);
    struct bias_matrix*B1 = bias_matrix_constructor(10);

    printf("\n""\n");
    printf("Neuron Activations");
    printf("\n""\n");
    for(int i = 0; i<A1->num_neurons; i++){
        printf("%.2f",A1->N[i].activation);
    }
    printf("\n""\n");
    printf("Weights");
    printf("\n""\n");
    for(int i = 0; i<W1->rows; i++){
        for(int j = 0; j < W1->cols; j++){
            printf("%.2f",W1->weights[i][j]);
        }
    }
    printf("\n""\n");
    printf("Biases");
    printf("\n""\n");
    for(int i = 0; i<B1->size; i++){
        printf("%.2f\n",B1->bias[i]);
    }

    printf("\n""\n");
    struct neuron_layer*A2 = layer_constructor(10);

    for(int i = 0; i<A2->num_neurons; i++){
        printf("%.2f\n",A2->N[i].activation);
    }
    printf("\n""\n");
    matrix_dot_product(A1,W1,A2);

    for(int i = 0; i<A2->num_neurons; i++){
        printf("%.2f\n",A2->N[i].activation);
    }

    printf("\n""\n");
    add_matricies(A2,B1);
    for(int i = 0; i<A2->num_neurons; i++){
        printf("%.2f\n",A2->N[i].activation);
    }
    return 1;
}